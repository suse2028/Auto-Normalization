{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2907d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import scipy\n",
    "import scipy.fft as fft\n",
    "import scipy.linalg as linalg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535be3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Initialize matrix for possible pathways\n",
    "\n",
    "path_base = np.empty((4,15))\n",
    "\n",
    "#Source methods from the LLM call and substitute entries in path_base\n",
    "\n",
    "path = []\n",
    "for i in range(len(path_base)):\n",
    "    entry = np.random.choice(path_base[i])\n",
    "    path = path + entry\n",
    "\n",
    "#Derive from the LLM call and place into following dict\n",
    "listed_probs = {}\n",
    "#Initialize probabilities\n",
    "path = dict(path)\n",
    "for value in listed_probs.values():\n",
    "    path.value(value) = value\n",
    "\n",
    "class Math(nn.Module):\n",
    "    pass\n",
    "\n",
    "#Easiest way to bypass difficult gradient calculations is to store prior states of the data\n",
    "class nonMath(torch.Autograd.Function):\n",
    "\n",
    "    def forward_hook(i, o, instance):\n",
    "        priors += i\n",
    "\n",
    "    def forward(priors, ctx):\n",
    "        priors = []\n",
    "        ctx.save_for_backward(priors)\n",
    "        forward_hook(2, 3, 4)\n",
    "        #Use built-in forward hook construct to store priors iteratively\n",
    "\n",
    "\n",
    "    def backward(ctx, p):\n",
    "        pass\n",
    "\n",
    "#Classify using requires_grad whether non_math or math\n",
    "classified_dict = {}\n",
    "for method in ref_methods: \n",
    "    output = method(data)\n",
    "    try:\n",
    "        output.backward()\n",
    "        method = Math()\n",
    "        setattr(Math, method.__name__ , lambda cls, *args, method=method: method(*args))\n",
    "    except RuntimeError as e:\n",
    "        method = nonMath()\n",
    "        classified_dict[f'{method}'] = 'non-math'\n",
    "\n",
    "\n",
    "\n",
    "#Class to dropout individual neurons in the overall matrix, not just the path (handled by the non_math class)\n",
    "class IndivDropout(nn.Module):\n",
    "    def __init__(self, epochs, path, prob):\n",
    "        super().__init()\n",
    "        epochs = self.epochs\n",
    "        path = self.path\n",
    "        prob = self.prob\n",
    "\n",
    "\n",
    "    def switch_neuron(self, path):\n",
    "        #Decide whether the class is mathematic or non-mathematic (relevant for graph leaf tracking)\n",
    "        for entry in path:\n",
    "            if isinstance(path[entry], nonMath):\n",
    "                return\n",
    "    \n",
    "#Evaluate the current neuronal state\n",
    "\n",
    "    def eval_neuron_state(self,reg, prob, current_epoch, epochs, path, data):\n",
    "        data = data\n",
    "        dev = np.std(data)\n",
    "        iter_delta = []\n",
    "        iterations_before_switch = 0\n",
    "        epochs_from_start = current_epoch\n",
    "        epochs = epochs\n",
    "        state_x = []\n",
    "        if epochs_from_start < epochs * 0.1:\n",
    "            for i in range(epochs_from_start, epochs_from_start + ((epochs * 0.1) - 1)):\n",
    "                state_x += (np.quantile(output, i +1  / 10) - np.quantile(output, i / 10))\n",
    "\n",
    "        for i in range(len(state_x)):\n",
    "            iter_delta += state_x[i] - np.quantile(data, i / 10)\n",
    "\n",
    "        if any(iter_delta) > dev:\n",
    "            self.switch_neuron()\n",
    "        elif any(x > 0 for x in state_x):\n",
    "            self.switch_neuron()\n",
    "        \n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "    def reactivate_neuron(reg, prob, current_epoch, epochs, path, data):\n",
    "        epochs_from_start = current_epoch\n",
    "        \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "def model_train():\n",
    "\n",
    "#STEP 2: Define a custom way that gradient actually flows\n",
    "#Two objectives here - local gradient descent (based on the score function) and global gradient descent (pattern path eliminations)\n",
    "\n",
    "#Local gradient descent\n",
    "    for epoch in range(len(epochs)):\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Global gradient_descent -> store the captured information here as a separate function\n",
    "\n",
    "stored_states = []\n",
    "def global_learning(path, iter_delta):\n",
    "    stored_states += path\n",
    "    #Take the iteration delta of switch_neuron\n",
    "    min_iter_delta = np.minimum(iter_delta)\n",
    "    ref_State = []\n",
    "\n",
    "\n",
    "\n",
    "    #Collecting all previous states, allowing for pre-deactivation initially for future potential dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1031aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL ARCHITECTURE: Combining CNN and RNN to pass time-based patterns over the data to recognize periodic conditions for normalization\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
